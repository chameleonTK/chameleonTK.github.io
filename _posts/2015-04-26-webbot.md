---
layout: post
title: How to create BOT!! SPIDER!! CLAWER!!
tags: [Archive, Code Code and Code]
thumbnail: "assets/feats/webbot/google-bot.jpg"
author: Pakawat Nakwijit
excerpt_separator: <!--more-->
color: rgb(19, 196, 165)
---

## TL;DR

ใครบอกว่า Bot เป็นเรื่องยาก? เรื่องยากความจริงแล้วก็แค่เพราะเราไม่รู้ /me เขียนบทความนี้ เพื่อให้ทุกคนลอง แล้วจะพบว่าการเขียน Bot เป็นเรื่องง่ายกว่าที่คิด

<!--more-->

<span class="tag-en">#ภาษาอังกฤษวันละคำ</span> วันนี้ ภูมิใจเสนอคำว่า "SPIDER" ออกเสียงว่า สะ-ไป-เด้อ แปลว่า "แมงมุม"
<span class="tag-en">#อีกรอบนะฮะ</span> "SPIDER" แปลว่า "แมงมุม"

แต่สำหรับหลายๆคน คงเข้าใจต่างออกไป <span class="tag-en">#แล้วมันคืออะไร</span>

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1itKMH3buOLi02DHLM95Zrorw0O7-OuV1" column=1 %}

จริงๆแล้ว WebBOT, SPIDER, CLAWER ในมุมมองของบางคน ไม่ใช่อะไรที่เกินไปกว่า โปรแกรมคอมพิวเตอร์ ที่ไล่เปิดเปิดเวปไซท์ขึ้นมา เพื่อเก็บรวบรวมข้อมูลต่างๆ จากนั้น ก็ ไต่ต่อจากลิงค์อยู่ในเวปไซท์ที่เปิดนั้น ไปเรื่อยๆ ไม่เหนื่อย <span class="tag-en">#ก็มันเป็นแค่โปรแกรมหนิ</span> <span class="tag-en">#แต่ควรมีดีเลย์นะ</span>

ตัวอย่างดังๆ ก็อย่างเช่น [Googlebot](http://en.wikipedia.org/wiki/Googlebot/) , [Bingbot](http://en.wikipedia.org/wiki/Bingbot/) ที่คอยรวบรวมเวปไว้สำหรับ <span class="tag-en">#search</span> ที่เราใช้ๆกันทุกวัน <span class="tag-en">#กูเกิลพังไปฉันคงมีชีวิตอยู่ไม่ได้</span>

ซึ่งการจะสร้างมันขึ้นมาก็ไม่ได้ยากอย่างที่คิด ลองมาดูกัน

### Requirements

> #### Python
>   //already installed in Ubuntu

> #### Pip
>   wget https://bootstrap.pypa.io/get-pip.py; 
>
>   sudo python get-pip.py;

> #### Requests
>   sudo pip install requests

> #### Beautiful Soup
>   sudo pip install beautifulsoup4

# Basic Principle


ก่อนที่จะทำแบบนี้ ก่อนอื่น ต้องมาทำความเข้าใจ การทำงานของ Website กันก่อน
website ที่เราเล่นๆทุกวันนี้ ส่วนใหญ่สื่อสารในรูปแบบที่ชื่อว่า HTTP ซึ่งเป็นรูปแบบที่คอมใช้ในการสื่อสารกัน <span class="tag-en">#เหมือนกับภาษา</span> เช่น ถ้าเป็นคนไทยคุยกัน ก็จะสื่อสารกันด้วยรูปแบบที่ชื่อว่า THAI

แต่ หลักการของ HTTP แต่ต่างจากภาษาทั่วๆไป คือ มันแบ่งคอมเป็น 2 ประเภท คือ <span class="tag-en">#client</span> และ <span class="tag-en">#server</span> ซึ่ง website จะอยู่ในเครื่อง server ส่วน web browser เช่นพวก <span class="tag-en">#Chrome</span> <span class="tag-en">#Safari</span> <span class="tag-en">#InternetExplorer</span> จะเป็น client

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1btzP1j8VcuBbV5WQash2yDq7iGXFr4C5" column=1 %}

ซึ่งเมื่อใส่ URL ที่ต้องการเข้าไปไป client จะไปถาม server ว่าเวปไซท์นี้มีเนื้อหายังไง ซึ่ง server ก็จะตอบเป็น HTML code <span class="tag-en">#พร้อมรายละเอียดอื่นๆด้วย</span>

<span class="tag-en">#ตัวอย่าง</span> HTML

```html

<html>
<head> </head>
<body> </body>
</html>

```
 

หลังจากนั้น <span class="tag-en">#WebBrowser</span> จะมีหน้าที่ แปลความ HTML <span class="tag-en">#มาแสดงเป็นภาพสวยๆ</span> ด้วยสิ่งที่เรียกว่า “Render Engine" ดังนั้น แต่ละ browser อาจจะแปลไม่เหมือนกันก็ได้ โดยเฉพาะ <span class="tag-en">#InternetExplorer</span> ที่มีปัญหาบ่อยๆ เพราะว่า ไม่ยอมแปลตามมาตรฐาน ทำให้บางเวปเปิดที่ brower อื่นแล้วสวย พอเปิดใน <span class="tag-en">#InternetExplorer</span> แล้วเน่า

ซึ่ง <span class="tag-en">#SPIDER</span> ของเราก็จะทำในลักษณะที่คล้ายๆกัน คือ

1. ส่ง HTTP ถามไปยัง url เป้าหมาย
2. แปลความ HTML ที่ได้รับ

# Let's Start


## ส่ง HTTP ถามไปยัง URL เป้าหมาย

เริ่มต้นด้วยการส่งไปถามข้อมูลจากหน้าเวปธรรมดาที่ไม่ต้องการ login อย่าง google.com สามารถทำได้ง่ายๆเพียง

```python
import requests
r = requests.get('https://www.google.com')
print r.text
```

หาทุกอย่างเป็นไปได้ด้วยดี ก็จะเห็น HTML code เต็มไปหมดเลย~

แต่ <span class="tag-en">#ในชีวิตจริงไม่ได้ง่ายแบบนั้น</span> หลายๆเวปที่จำเป็นต้องกรอก username/password หรือ form รูปแบบต่างๆ <span class="tag-en">#แล้วฉันจะทำยังไง</span>? <span class="tag-en">#แต่มันก็ไม่ได้ยากอย่างที่คิดหรอกนะ</span>

ซึ่งเราจะใช้ Chrome เป็นเครื่องมือในการแกะรอยครั้งนี้ <span class="tag-en">#ตามวิธีต่อไปนี้</span>

* เปิด chrome แล้วพิมเวปที่เราจะ login
* กด ctrl+shift+J เพื่อ เปิด console ขึ้นมา
* กดเลือก tab Network

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1fd9HR8NrS2LNRA1oo17QIv2xAC3BQQkt" column=1 %}

* ลองกรอกฟอร์มแล้วส่ง ข้อมูล มั่วๆ จะเห็นว่า มันเกิดการส่งข้อมูล จากนั้นหาก้อนที่เป็นข้อมูลที่กรอกไป

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1hnrbzJsJFFPLrHeOpaKlVnzuNn5cYQfE" column=1 %}

* หากกดเข้าไปดูก็จะได้ข้อมูลครบทุกอย่างที่เราต้องการ ซึ่งจะประกอบด้วย

    * Url ที่เป้าหมายสำหรับการ login
    * ชนิดของคำถามที่จะส่งไปหา server มักจะเจอเพียง GET [ใช้ requests.get], POST [ใช้ requests.post]
    * ข้อมูลที่ต้องส่งไปเพื่อ login

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1Di3mNMVqfYYcKlKzyHR96gu-aG1u7neQ" column=1 %}

* ลุยโค้ดกันเลย

```python
import requests
with requests.Session() as session:
    payload = {"member%5Bemail%5D": "....", 
               "member%5Bcrypted_password%5D": "...",
               "persistent%5Bremember%5D": "1",
               "action": "login",
               "redirect":"Lw%3D%3D"}
    r = session.post("http://pantip.com/login/authentication", data=payload)
    print r.text
```

* สังเกตุได้ว่า โค้ดค่อยข้างเปลี่ยนไปมาก <span class="tag-en">#เพราะอะไร</span>? สิ่งที่สำคัญที่มาพร้อมกับการ login นอกจาก การส่งข้อมูลแล้ว มันก็คือ การบอกให้ระบบรู้ว่า เรายังคงอยู่ในฐานะที่ login อยู่ <span class="tag-en">#ฉันยังไม่ได้ออกจากระบบ</span> ซึ่งนั้นจำเป็นจะต้องมีการเก็บ Session ซึ่งเก็บสถาณะให้ระบบสามารถตรวจสอบได้ 

สำหรับใครที่สนใจ Requests ท่ายากกว่านี้ [คลิ๊ก ศึกษา Requests เพิ่มเติม](http://docs.python-requests.org/en/latest/user/quickstart/)


# แปลความ HTML ที่ได้รับ

หลังจากที่ผ่านความยากลำบากเพื่อให้ได้ HTML จาก server แล้ว <span class="tag-en">#งานต่อมา</span> คือ การแปลความหมายของ HTML <span class="tag-en">#ควรจะเริ่มยังไงดี</span>

พูดถึงมาตั้งนานละ HTML HTML HTML แล้ว ไอ้ HTML <span class="tag-en">#คืออะไร</span>?

HTML เป็น <span class="tag-en">#MarkupLanguage</span> ซึ่งหมายถึง ภาษาสำหรับการแสดงผลโดยไม่มีการคำนวนเข้ามาเกี่ยวข้อง ดังนั้นจึงเป็นไปไม่ได้ที่จะมีใครมาบอกว่า ผมเขียนโปรแกรม <span class="tag-en">#เครื่องคิดเลข</span> ด้วยHTML สิ่งที่ทำให้เวปเกิดการ movement คือส่วนที่เป็น <span class="tag-en">#javascript</span>, <span class="tag-en">#coffeescript</span>, <span class="tag-en">#dart</span> … ต่างหาก

โครงสร้าง HTML เป็นโครงสร้างที่อยู่ในรูปแบบที่เรียกว่า <span class="tag-en">#tree</span>

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1tPure3yMWVhIF6J390mEa1zjBmW5m4SI" column=1 %}

โดยสิ่งที่อยู่ใน <> จะเรียกว่า <span class="tag-en">#tag</span> เช่น <html> , <body> , <p> , <img> แต่ละ <span class="tag-en">#tag</span> ต้องมี tag เปิด และ tag ปิด แต่ อาจจะไม่มี tag ปิดบ้าง <span class="tag-en">#นิสหน่อย</span> ซึ่งเกิดจาก ความขี้เกียจทาง <span class="tag-en">#ประวัติศาสตร์อันยาวนาน</span> ของ HTML นอกจากนี้ ก็คือ สิ่งที่เป็นส่วนขยายเรียกว่า <span class="tag-en">#attribute</span> เช่น

```html
<a href="www.google.com"> ... </a>
```

<span class="tag-en">#href</span> เป็น attributeของ tag `<a>` โดย attr href มีค่า = `"www.google.com"`

หลักจากเข้าใจแล้วว่า <span class="tag-en">#HTML</span> คืออะไร แต่จะรู้ได้อย่างไรว่า จุดที่เราสนใจ คือ tag อะไร <span class="tag-en">#เข้าประเด็น</span>

เราจะยังคงสามารถใช้ Chrome เป็นเครื่องมือในการแกะรอยได้เช่นเดียวกัน <span class="tag-en">#หนิมันไว้เปิดเวปหรือไว้แฮ๊กวะ</span>

* ให้ click ขวาในส่วนที่เราสนใจ เลือกหัวข้อ Inspect Element

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1e2gXjoUA0e3X0DH-H_T_o3oHOZOPK9DA" column=1 %}

* เลือก tag ให้ตรงตามที่ต้องการ โดยดูจากแรงเงา <span class="tag-en">#สีน้ำเงิน</span>

{% include aligner.html images="https://drive.google.com/uc?export=view&id=1IehsqZWBhbkHUxHsvyNKALoLTxRvPhpW" column=1 %}

* ศึกษารูปแบบโค้ดจาก console ที่ขึ้นมา

เมื่อรู้แล้วว่า ส่วนที่สนใจคือ tag อะไร ก็เริ่ม ใช้ <span class="tag-en">#BeautifulSoup</span> กันได้เลยยย ซึ่ง BeautifulSoup เป็น library ที่ใช้ในการแปลความ HTML ให้ออกมาอยู่ในรูปแบบ tree ซึ่งสามารการใช้ค้นหา tag ที่ต้องการ โดย
```python 
body = soup.findAll("body")  
```

ซึ่งจะได้มาเป็น list ตัวแทนของ tag <body> และ สามารถดึง ข้อความใน tag หรือ attribute ได้โดย

```python 
body = soup.findAll("body")  

print body[0].text  <span class="tag-en">     #แสดงค่าข้อมูลที่อยู่ภายใน</span> tag
print body[0][“class"] <span class="tag-en">  #แสดงค่า</span> attribute class ของ tag 
```

่ศึกษา BeautifulSoup เพิ่มเติม ซึ่งเมื่อนำมาประกอบกับโค้ดเดิมจะได้

```python
import requests
from bs4 import BeautifulSoup
with requests.Session() as session:
    payload = {"member%5Bemail%5D": "....", 
               "member%5Bcrypted_password%5D": "...",
               "persistent%5Bremember%5D": "1",
               "action": "login",
               "redirect":"Lw%3D%3D"}
    r = session.post("http://pantip.com/login/authentication", data=payload)
    r = session.get("http://pantip.com/tag/ชีวิตวัยรุ่น")
    soup = BeautifulSoup(r.text)
    tag_a = soup.findAll('a')
    for tag in tag_a:
        print tag["href"]
```

หากทุกอย่างเป็นไปอย่างถูกต้อง <span class="tag-en">#มันจะไม่บั๊คนะ</span> เราจะได้ลิงค์ทั้งหมดปรากฏ <span class="tag-en">#เย้</span> <span class="tag-en">#จบซะที</span>

# … END …

แต่อย่างไรก็ตามทั้งหมดนี้ ก็เป็นเพียง <span class="tag-en">#Basic</span> เบื้องต้นของการทำ <span class="tag-en">#SPIDER</span> ในฉบับสมบูรณ์ยังมีอีกหลายส่วนที่ต้องศึกษา เช่น การทำให้โปรแกรมสามารถไต่ไปยังลิงค์ต่อไปได้อย่างต่อเนื่อง <span class="tag-en">#เพิ่มอีกนิสเดียว</span>, การคัดกรองลิงค์, การป้องกันไม่ให้เจอลิงค์กับดัก <span class="tag-en">#คืออะไรหว่า</span> <span class="tag-en">#ไม่บอกหรอก</span> และอีกมากมาย~

สุดท้ายนี้ ขอฝากคำพูดนึงไว้

<div class="blockquote">

ความรู้สามารถใช้ได้ในทางที่ดี และ ทางที่ไม่ดี <span class="tag-en">#แยกให้ออกว่าอะไรคือสิ่งที่ควร</span> แล้วจะได้ไม่ต้องกังวลกับผลลัพย์จากสิ่งที่ทำ :))
</div>

ปล. ขออนุญาต และขอขอบคุณ [Pantip.com](http://pantip.com) ที่เป็นตัวอย่างในครั้งนี้

# Credit
* [A Simple Web Bot with Requests and BeautifulSoup](http://stefan.sofa-rockers.org/2012/02/21/simple-web-bot-requests-and-beautifulsoup/)
* [How to “log in" to a website using Python's Requests module?](http://stackoverflow.com/questions/11892729/how-to-log-in-to-a-website-using-pythons-requests-module)

